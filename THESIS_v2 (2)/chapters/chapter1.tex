
\chapter{INTRODUCTION}

% \newthought{There's something to be said} for having a good opening line. Morbi commodo, ipsum sed pharetra gravida, orci  $x = 1/\alpha$ magna rhoncus neque, id pulvinar odio lorem non turpis \citep{Eigen1971, Knuth1968}. Nullam sit amet enim. Suspendisse id velit vitae ligula volutpat condimentum. Aliquam erat volutpat. Sed quis velit. Nulla facilisi. Nulla libero. Vivamus pharetra posuere sapien. Nam consectetuer. Sed aliquam, nunc eget euismod ullamcorper, lectus nunc ullamcorper orci, fermentum bibendum enim nibh eget ipsum. Donec porttitor ligula eu dolor. Maecenas vitae nulla consequat libero cursus venenatis. Nam magna enim, accumsan eu, blandit sed, blandit a, eros.
% $$\zeta = \frac{1039}{\pi}$$


% For an example of a full page figure, see Fig.~\ref{fig:myFullPageFigure}.

\section{Background and Research Motivation}
Although there is a wide range of educational materials available, students often struggle to use them effectively due to the lack of clear structure and guidance—especially in online learning environments. These issues are further complicated by organizational problems and a lack of communication, collaboration and problem-solving among peers. One area where this is particularly evident is in mathematical modeling (MM), a core competency in STEM education benefits significantly from collaborative learning approaches. However, students frequently lack access to high-quality support in developing this skill. Contributing factors include a shortage of well-prepared educators able to facilitate mathematical discourse, as well as personal barriers such as social anxiety or low confidence in group settings. Given the trend towards learner-centered and inquiry-based instruction, there is an increasing demand for adaptive, supportive, communicative strategies that promote mathematical thinking and real-world problem-solving.

Recent advances in large language models (LLMs) offer promising solutions. LLMs demonstrate strong capabilities in mathematical reasoning and can solve many problems with different levels correctly \cite{liu2024mathbench}. Beyond problem-solving, the LLM- based agents may demonstrate human-like behaviors and social interactions which in turn may facilitate realistic and personalized learning environment for the user. This opens new opportunities for adaptive education practice, with students experiencing peer-like exchanges of ideas and personalized support—especially when engaging with mixed-ability groups.


\section{Research Problem}
In both traditional and online educational settings, student interaction is a fundamental component of effective learning. This interaction is not limited to exchanges with the instructor but also includes peer-to-peer engagement, which plays a significant role in developing communication and collaboration skills. Students actively participate in classroom discourse through a variety of actions, such as asking questions, offering opinions, debating solutions, or providing explanations to others. These behaviors not only reinforce content understanding but also cultivate critical thinking and social-emotional competencies. Through regular interactions with multiple individuals, students learn to navigate different perspectives, articulate their reasoning, and build confidence in expressing their ideas within a community of learners.

However, current one-to-one tutoring chatbots exhibit a critical limitation: they simulate conversation with only a single agent, thereby restricting the diversity of interaction available to students. While these systems can provide personalized feedback and instruction, they fall short in recreating the social and collaborative aspects of classroom learning. Students interacting with a single chatbot are deprived of the experience of negotiating meaning, managing turn-taking, or engaging with diverse perspectives, all of which are fundamental to real-world communication and group problem-solving. This raises the issue of researching virtual classroom simulations using multiple agents interacting with students.

\section{Research Objectives and Scope}
This study aims to explore the potential of large language model LLM-powered multi-agent systems in supporting high school students' development of mathematical modeling skills through collaborative problem-solving. A central focus of this study is the management of conversational turn-taking among agents. In human group learning scenarios, the timing and coordination of turns in discussion significantly influence the flow of conversation and the overall effectiveness of learning. Recognize the importance of turn-taking between agents, this study aims to clarify the limitations of current turn-management strategies in existing dialogue systems. It will analyze previous approaches, identify their shortcomings, and propose improvements that enable AI agents to make more contextually appropriate, proactive decisions about when and how to contribute in multi-party dialogues. The goal is to enhance the naturalness, coherence, and pedagogical value of agents.

The research centers on high school mathematics problem-solving tasks as the primary domain for experimentation and evaluation. These tasks provide a suitable context for examining how AI agents can collaborate and support students in navigating complex cognitive and communicative challenges.

\section{Thesis Structure}
This thesis is organized into five chapters. Chapter 1 introduces the research background, highlighting challenges in traditional education and the potential of LLM-powered multi-agent systems for collaborative mathematical modeling, defining the research problem and objectives. Chapter 2 reviews relevant literature, covering the evolution of AI in education, one-to-one tutoring, and the concept of virtual classrooms using multi-agent systems, identifying key research gaps. Chapter 3 details the proposed methodology, outlining the design goals and architecture of the multi-agent system, including its event-driven nature, stage management based on pedagogical principles, proactive turn-taking mechanism, and role-based agent customization. Chapter 4 describes the experimental setup used to evaluate the system, including task design, dataset collection, the LLM-as-a-judge evaluation method, and presents the main findings and discussion. Finally, Chapter 5 concludes the thesis by summarizing the contributions, acknowledging limitations, discussing ethical considerations, and suggesting avenues for future work.
