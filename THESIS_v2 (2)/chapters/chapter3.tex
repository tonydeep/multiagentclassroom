%% Chapter 3
\chapter{METHODOLOGY}
In this chapter, We present a pioneering methodology for designing AI agents that work alongside students, each with unique roles and personalities, blending autonomy. Powered by an event-driven architecture, these agents engage in real-time, creating a dynamic and responsive learning environment. Grounded in educational theories, the approach below structures interactions to maximize engagement and transform group learning into an interactive, AI-enhanced experience. The system is illustrated in Figure~\ref{fig:multi_agent_learning_overview}.

\section{Design goals}
AI-Human collaboration can be designed to achieve specific outcomes, such as solving a mathematical problem, while also fostering participant engagement and learning progress. This perspective led to the following design goals:

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/1.pdf}
    \caption{Multiple intelligent agents supporting student learning.}
    \label{fig:multi_agent_learning_overview}
\end{figure}


\begin{itemize}
    \item \textbf{Agents have distinct roles} within the collaboration, operating independently rather than uniformly, thus forming a true collaborative team.
    %\item Agents can be guided to behave differently, allowing humans to steer the team dynamics generated by the system.
    \item \textbf{Iterative interactions} allow both agents and humans to teach and give feedback, enabling humans to both coach and be coached by the agents.
    \item \textbf{Agents follow a pedagogical approach} to problem-solving, ensuring that their contributions support effective learning outcomes for the human participant.
\end{itemize}
To achieve the outlined goals, Agents will be designed with the following features:
\begin{enumerate}
    \item Agents need to be aware of the environment (conversation, participants) to enable realistic collaboration with human participants across various problem stages.
    \item Agents must possess complete autonomy, allowing them to decide whether to act or refrain from acting at any point in response to environmental changes, without predetermined decision sequences. 
    \item Agents should provide customizable options for team roles, personality traits, and knowledge depth to enhance user experience. 
\end{enumerate}
To address the above three requirements, a three-module system based on event-driven architecture is designed as shown in Figure~\ref{fig:system_architecture}, which will be discussed in the following sections.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/2.pdf}
    \caption{The three-module system based on event-driven architecture.}
    \label{fig:system_architecture}
\end{figure}

\section{Event-driven Architecture}
In a one-to-one chatbot application, the condition for an agent to respond is that there is a new message from the user. However, this becomes more complicated when multiple agents are involved at the same time, so a more expansive, realistic definition of how agents participate in a conversation is needed.

\textit{\textbf{Environment}}. With chatbot applications, the environment here can be understood as the chat conversation history, the stages that appear in the discussion, who participates, and even time is also the information dimension that the agent needs to know.

\textit{\textbf{Events}}. In human conversations, they start thinking or responding to others when they receive a specific trigger, which can be a word, action, gesture or look. Similarly, agents can imitate this to do their work when the environment sends them events. In the implementation of this system for online chat-based dialogues, two categories of events are defined:
\begin{itemize}
    \item \textbf{New message}: This event is triggered whenever a participant sends a message. The agents will begin to perform thinking in response to that message.
    \item \textbf{Silence pause}: This trigger activates when no participant has sent a message for a set duration (e.g. 10 seconds). It enables the AI to contribute during moments of inactivity - unless the lesson has ended.
\end{itemize}
Events will be processed sequentially. The AI agent's contribution triggers should be customizable, allowing responses to all messages or only when directly addressed, based on design or user preferences. 
Moreover, the system is designed to be easily expandable for new capabilities in the future. In the application of AI robots for education, researchers have explored incorporating contextual and non-verbal cues—such as eye gaze (e.g., looking at the addressee), breathing patterns, pitch changes and the user's physical status — to determine whether the AI should engage at a given moment in the conversation. These signals can be treated as input events that trigger agents to act appropriately in different situations.

\textit{\textbf{Shared event timeline}}. Events create a unified timeline, establishing a shared sequence of activities across the entire system. This design ensures that all agents operate with the same level of information and situational awareness. The shared timeline helps keep the agent's behaviors and interactions in a consistent framework. 
At intervals, each AI agent monitors the shared event timeline (Figure~\ref{fig:event_timeline_check}):

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/3.pdf}
    \caption{AI agent checking the shared event timeline.}
    \label{fig:event_timeline_check}
\end{figure}

\begin{itemize}
    \item Upon a new event, the agent can choose to either take action by sending a message or remain inactive.
    \item When the agent sends a message, an event is added to the event timeline. 
    %\item This cycle of event to decision to action or inaction powers the agents’ autonomy, as they are able to observe, make decisions, and take action at any time. This is the same level of autonomy a human would have in a team. 
\end{itemize}

\section{Stage Module}
    \subsection{Educational Theories and Pedagogical Approaches}
    In practice, a collaborative problem-solving process typically consists of multiple stages. There is evidence suggesting that structured collaborative learning, where students work together with multiple discussion stages, clear roles, and shared goals, tends to be more effective than simply having the tutor give \textbf{direct answers} to students. This approach can enhance student engagement and positively influence learning outcomes.

    In accordance with the 2018 General Education Program for Mathematics, Vietnam \cite{moet2018circular32}, the essential components of mathematical competency include the ability to think and reason mathematically, mathematical modeling ability, problem-solving ability, mathematical communication ability, and the ability to use mathematical tools and resources. Each component of mathematical competency in general, and problem-solving ability in particular, is specifically demonstrated through the following criteria and indicators:
    \begin{itemize}
        \item Recognizing and identifying the mathematical problem needing solving.
        \item Selecting and proposing methods and solutions to solve the problem.
        \item Using appropriate mathematical knowledge, skills (including tools and algorithms) to solve the posed problem.
        \item Evaluating the proposed solution and generalizing it to similar problems.
    \end{itemize}
    The components mentioned above not only fully reflect the sub-competencies of mathematical problem-solving ability but also describe the process by which students solve problems. Similarly, in \textit{How to Solve It} by George Polya \cite{polya1945how}, the process of solving a mathematical problem is articulated through four distinct stages:
    \begin{itemize}
        \item \textbf{Stage One – Understanding the Problem}.
        \item \textbf{Stage Two – Devising a Plan}.
        \item \textbf{Stage Three – Carry out the Plan}.
        \item \textbf{Stage Four – Looking back}.
    \end{itemize}
    Therefore, this system is designed to address mathematical questions through four distinct stages, during which students engage in collaborative discussion to achieve the specific objectives of each stage. Detailed description in \ref{chap:stage}.
    \subsection{Stage manager agent}
    To create realistic conversations, every dialogue initiates at Stage 1, establishing a structured starting point. A collaboration stage manager agent is responsible for continuously monitoring and evaluating the dialogue history, comparing it against predefined criteria specific to each stage. This agent dynamically determines when the objectives of the current stage have been sufficiently met. Each stage is designed with its own set of tasks, carefully crafted to align with the stage’s goals, ensuring that the dialogue progresses logically and purposefully.
    
    To avoid agents directly stating the solution or discussing the wrong order of a task, all tasks will be marked as completed or incomplete. The stage manager uses the CoT prompt to analyze the situation and decide to update the status, thereby ensuring the simulation remains coherent and goal-oriented throughout its progression.

\section{Turn-takings Module}

    \subsection{Definition}
    For a conversational agent to engage proactively, it must understand and manage turn-taking, determining who speaks next at the end of each turn. In one-on-one chatbot interactions, the next speaker is always clear when a turn is yielded. In multi-party settings, this becomes less certain, as multiple potential speakers could take the turn.
    Turn-taking in conversations is governed by a set of rules \cite{Inner}:
    \begin{itemize}
    \item Turn-allocation: The current speaker may select the next speaker, often using address terms (e.g., “What about you, Alice?”).
    \item Self-selection: If the current speaker does not select a next speaker (e.g., “I went to Ho Chi Minh city last month.”), then any party can self-select to take the floor.
    \item If no other party self-selects, the current speaker may continue.
    \end{itemize}

    \subsection{Challenges}
    Unlike multi-agent systems with Standardized Operating Procedures – SOPs (it is a pre-defined step-by-step process designed to help agents resolve issues), the classroom scenario is a dynamic group chat without a strict workflow, requiring agents to determine appropriate speaking times on the fly \cite{SimClass}. This dynamism requires that agents make real-time decisions regarding when and how to participate appropriately in the discourse.
    
    In the context of multi-participant dialogues, the design paradigm must address not only the content of the response (``What") but also the timing of the intervention (``When") and the target audience for the response (``Who") \cite{mao2024muca}:

    \begin{itemize}
        \item \textbf{What}: Selecting appropriate content is important in both one-to-one and multi-participant chatbot design. Content may vary based on domain-specific goals or task requirements and may include adjustments to delivery style (e.g., message length or style, tone).
        \item \textbf{When}: Unlike single-user scenarios, where the chatbot typically responds to each user message, multi-participant environments require more nuanced timing strategies. The agent must assess whether to interject, wait, or remain silent, striking a balance between excessive responsiveness and disengagement. This requires a complex decision-making mechanism to manage the dynamics of group chats.
        \item \textbf{Who}: Multi-participant chatbots must identify the intended recipient(s) of their messages—whether it's a specific person, a small group, or everyone. This decision can be informed by analyzing conversational history, participant roles or prior messages to ensure contextually relevant responses.
    \end{itemize}
    Therefore, the capabilities of large language models (LLMs) are leveraged not only for generating direct responses to user inputs but also for facilitating turn-taking decisions by identifying the next appropriate speaker. The following outlines two distinct approaches to this process.

    \subsection{Next speaker prediction approach}
    In the SimClass \cite{SimClass} implementations, a speaker management agent is designed to select speakers. This approach manages turn-taking in conversations by primarily leveraging conversation history to predict the next speaker, often treating the AI as a reactive agent:
        \begin{center}
        $f: H, S \rightarrow a$
        \end{center}
    Where, $H$ is conversation history, $S$ is current stage, and $a$ is next speaker agent.

    Several studies \cite{Inner} have shown that next-speaker prediction performs well when explicit turn-allocation cues are present. However, Bailis et al. \cite{Whonextspeak} pointed out that while this approach is potentially effective, it lacks autonomy for individual agents since agents are passively selected by other agents. In addition, after determining the next speaker, those existing works tend to use predefined speaker personas as additional input to guide response generation. These additional inputs and profiles are fixed and static during conversations, instead of changing through time as humans did. Intuition is that decisions to self-select and participate are largely influenced by internal processes, such as a participant’s interest, relevance, or motivation to engage, which are not easily observable from conversation. 
    Realizing the limitations of this method, we will approach the problem from a different approach.

  \subsection{Can agents have minds of their own? – A proactive approach}
    \subsubsection{Motivation}
    \textit{\textbf{Realistic example}}. Imagine students discussing their group project tasks. As they hear their friends share ideas, they absorb their suggestions, reflect on their own contributions, and form an internal stream of thoughts. At times, they feel a compelling urge to speak up — perhaps to ask for clarification or when someone mentions an idea they also considered, sparking their eagerness to contribute. With that intent, they wait for a suitable moment to add to the conversation naturally.

    Enabling agents to independently decide the speaking order could be crucial for them to fulfill their social roles effectively, creating more natural and efficient conversations. The approach explored here aims to leverage these internal streams of thought to enable agents to self-select actions and participate proactively in conversations. This approach is used in this system to select the speaker at each time point and compared to baseline is the ``next speaker prediction" approach above.  
    
    \textit{\textbf{Self-selection problem}}. This method takes into account the influence of each agent's thoughts on the conversation, reducing unnatural speaker selections and prioritizing thoughts that are considered urgent to everyone, such as an agent discovering that a classmate has made a mistake. This improves the problem of self-selection.

    \subsubsection{Processing}
    As shown in the Figure \ref{fig:system_architecture}, the process will start when the environment returns a new event. Notably, in the setting when a new event appears (usually new messages), they will be paused for a random amount of time (1-5s) before being sent to the agents, this helps to reduce the number of LLM requests in a short period of time and allows users to have more space to contribute to the conversation. The process then proceeds in three stages: agents think independently, evaluate thoughts, and select appropriate speakers.

    \textit{\textbf{Thinking}}. Thinking is not inherently interactive, as it does not involve direct engagement with the external environment. Instead, it is a preparation process—represented by the principle of “think before respond”—that supports more intentional and context-appropriate actions.   

    At the start of a new event, agents perform a function called thinking. Using the available data, thinking produces a thought, which outlines the plan for the next message or action to advance their objectives. At the same time, agents decide whether to ``speak'' or ``listen''. The agent draws on its memories to gather stimuli that shape its thoughts. These stimuli, factors such as ongoing conversations, the agent’s roles, or previous thoughts, influence its current thinking. This process helps agents generate coherent thoughts and be more proactive in determining when to speak.

    \textit{\textbf{Evaluate thoughts}}. Considering the agent’s thoughts, what elements beyond previous utterances shape its decision to engage in the conversation? Here, the evaluator agent will evaluate the thinking based on two main types of factors \cite{Inner}:
    
    \noindent \textbf{Internal factors} come from agents:
    \begin{itemize}
        \item \textbf{Relevance}: Agents were more likely to contribute when the discussion aligned with their knowledge, roles or recent thoughts. On the other hand, they often refrain from speaking when they sense it’s not the right moment to speak up.
        \item \textbf{Expected impact}: Agents were inclined to share thoughts they believed would introduce new things, guide the conversation’s direction, or deepen its substance.
        \item \textbf{Urgency}: This is important when agents perceive their contributions as time-sensitive or necessary to correct errors or clarify misunderstandings.
    \end{itemize}
    \noindent \textbf{External factors} come from the environment (conversation, other people involved):
    \begin{itemize}
        \item \textbf{Coherence}: Agents prioritized thoughts that logically connected to the prior utterance, avoiding ideas that could disrupt the conversational flow.
        \item \textbf{Redundancy}: Agents avoid repeating points already made, choosing to withhold contributions that seem redundant.
        \item \textbf{Balance}: Agents monitored their own participation relative to others, striving to encourage quieter participants to speak.
    \end{itemize}
    These factors will influence the agents' intrinsic motivation score, which reflects their desire to engage in conversation : Low, Neutral , High or Very High. 
    
    The evaluation process employs a prompt-based evaluation approach: it includes a prompt that outlines evaluation instructions and specifies the criteria; a structured Chain of Thought (CoT) that details the steps for assessment; and a scoring function to quantify the results. (output rating 1.0 - 5.0 for internal and external score). See prompt at \ref{sec:evalpromt}.

    \textit{Who next?}. The score of each thought is calculated according to the formula:
    \begin{equation*}
        \text{Score}_p = s_p * \lambda^{\tau - \tau_p}
    \end{equation*}
    Here, $s_p$ denotes the predicted rating for participant $p$. The final score is adjusted based on the duration of the agent's silence. The assumption is that, generally, the longer an agent remains silent, the greater their motivation to speak in order to maintain their presence in the conversation. The parameter $lambda$, set at $1.02$, represents the rate at which the motivation score increases. $\tau$ is the current turn, and $\tau_p$ is the last time when the party $p$ spoke. If the agent's score passes a threshold, they become a speaker.

    \textit{\textbf{Poor thinking}}. Inspired by reinforcement learning principles, the environment provides positive rewards when the agent executes effective actions. If the agent generates low-quality thoughts—such as considering actions that duplicate previous contributions by others or repeat its own earlier reasoning—and these receive a score below a defined threshold, the system sends a reminder signal. This signal is incorporated into the agent’s next prompt to guide its future responses. The purpose of this mechanism is to encourage the agent to produce thoughts that become increasingly more contextually relevant over time.

\section{Role-Based Agentization Module}

    \subsection{Roles from pedagogical principles}
    Classroom interaction behaviors can be categorized based on widely pedagogical principles \cite{schwanke1981classroom}:
    \begin{itemize}
        \item Teaching and Initiation (TI): Introduces new concepts, provides explanations, and encourages student feedback to initiate learning.
        \item In-depth Discussion (ID): Promotes detailed discussions through question-answer, critical thinking, and dialogue to deepen student understanding.
        \item Emotional Companionship (EC): Creates a supportive learning environment by encouraging students, fostering community, and providing emotional motivation.
        \item Classroom Management (CM): Ensure an effective learning environment by maintaining discipline, organizing activities.
    \end{itemize}
    To enhance students' learning efficiency, the agents must adopt the above mentioned behaviors. Ensuring diversity and comprehensive coverage of these agents in the classroom is essential, achieved by establishing distinct Class Roles (denoted as $R=\{r_i\}_{i=1}^{|R|}$, where each $r_i$ denotes a certain role) in the virtual classroom.

    Notably, the system allows for flexible customization of multiple agents with distinct roles, tailored to various user interests or educational objectives. This enables users or administrators to design diverse classroom scenarios—for instance, a fully staffed virtual classroom (teacher and students) or a role-playing environment featuring agents representing different societal roles. In this study, the chosen configuration focuses on the student-to-student interaction model because it is suitable for solving mathematics problems. Three classmate agents were implemented, each assigned specific roles in accordance with the aforementioned principles:
    \begin{itemize}
        \item One group leader agent, incorporating roles in TI and CM.
        \item Two classmate agents, each combining roles in TI, ID, and CM.
    \end{itemize}

    \subsection{How to design}
    This work draws on agentic design principles inspired by the CrewAI platform \cite{crewai2025}, which supports the creation of specialized AI personas capable of effective collaboration and generating high-quality outputs tailored to specific objectives. The design of these agents emphasizes the impact on: Output quality, Collaboration effectiveness, Task performance and System scalability. Core Principles of Effective Agent Design:
    
    \noindent \textit{\textbf{Role-Goal-Backstory Framework}}  
    \begin{itemize}
        \item \textbf{Role}: specifies the agent’s function and domain of expertise. It should be clearly defined and specialized, aligned with real-world professional roles, and reflective of relevant domain knowledge.
        \item \textbf{Goal}: guides the agent’s actions and informs its decision-making process. It should be explicitly stated, outcome-oriented.
        \item \textbf{Backstory}:Add contextual depth, shaping the agent's interactions. Describe expertise, style, interests, and remain consistent with both the assigned role and the overarching goal.
    \end{itemize}
    
    \noindent \textit{\textbf{Crafting Effective Tasks}}
    \begin{itemize}
        \item \textbf{Task Description}: The Process. The description should focus on what to do and how to do it.%, including:
            % \begin{itemize}
            %     \item Detailed instructions for execution
            %     \item Context and background information
            %     \item Scope and constraints
            %     \item Process steps to follow
            % \end{itemize}
        \item \textbf{Expected Output}: The Deliverable. The expected output should define what the final result should look like.%:
            % \begin{itemize}
            %     \item Format specifications 
            %     \item Structure requirements
            %     \item Quality criteria
            %     \item Examples of good outputs
            % \end{itemize}
    \end{itemize}
    Following the guidelines, the design will be clearer, enabling customization and installation of agents with diverse roles, styles, and functions for various purposes. See example at \ref{sec:roles}

    \subsection{Information of agent}
    \textit{\textbf{Environmental awareness}}. Agents must maintain awareness of a shared timeline. Upon the occurrence of a new event, each agent is prompted to make a decision—such as whether to speak or remain silent.

    \textit{\textbf{Class Stage}}. Agents must have information about the problem's stage, the steps to be taken, and the goals to be achieved in order to move to another stage.

    \textit{\textbf{Memory}}. For LLM-based agents, memory management mechanisms are crucial components for generating more natural and consistent responses. Memory can be divided into the following types:
    \begin{itemize}
        \item First, there is a \textbf{working memory}, named History, which maintains the past k turns of conversation:
        \begin{equation*}
        H = \{u_{n-k+1}, u_{n-k+2}, ..., u_n\},
        \end{equation*}
        \item Second, each agent maintains a \textbf{short-term memory}. This encompasses the record of thoughts produced during the discussion's thinking process. It maintains the agent's analyses, intentions, and tracks changes in their thinking:
        \begin{equation*}
        \text{shortTermMemory} = \{t_{n-k+1}, t_{n-k+2}, ..., t_n\},
        \end{equation*}
        \item Additionally, the system can incorporate long-term memory, which involves storing information about past interactions between the agent and the user in a database and retrieving it as needed. This mechanism supports greater personalization by enabling the agent to adapt its behavior based on the user’s history. However, in the current implementation, this feature has not been integrated due to the absence of sufficient user interaction data. Nonetheless, it represents a promising direction for future AI applications in education.
    \end{itemize}




