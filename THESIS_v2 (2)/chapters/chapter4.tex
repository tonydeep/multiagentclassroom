\chapter{EXPERIMENTAL SETUP AND EVALUATION}

\section{Method}

\subsection{Tasks}
Evaluating an entire conversation presents significant challenges, particularly in multi-party dialogues, as altering the speaker at any given turn can influence the trajectory of subsequent interactions. Drawing inspiration from MT-Bench-101 \cite{bai2024mt}, which focuses on conversation evaluation, this study proposes the generation of simulated conversations tailored to specific objectives or scenarios to assess the capabilities of conversational agents. The conversation will be created first as a context, then a few agent turns will be created for evaluation. For a conversation between students solving a math problem, we chose four types of tasks to create an assessment scenario, Figure \ref{fig:categories}:

% h or h!
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/categories.png} 
    \caption{Categorize the various scenarios based on each task. EC (Emotional Companionship), ID (In-depth Discussion), and CM (Classroom Management).}
    \label{fig:categories}
\end{figure}

\begin{itemize}
    \item \textit{Task 1 - Error propagation}: The scenarios are constructed to evaluate the agent’s ability to identify user errors. In simpler situations, errors occur close to the agent's response, making detection easier. In more complex scenarios, the error is introduced earlier in the conversation, distant from the agent’s turn, and is further obscured by the presence of other participants who fail to recognize or address the error.
    \item \textit{Task 2 - Self-correction and Self-affirmation}: Self-correction refers to the agent's ability to correct mistakes. When an error points out their mistake, they will recognize it and correct it. In contrast, self-affirmation refers to an agent’s ability to assert the correctness of its own response when challenged by another participant who provides an incorrect correction. LLMs often struggle to maintain confidence in their responses when confronted with user disagreement. This type of scenario is also designed to evaluate the LLM’s mathematical reasoning capabilities.
    \item \textit{Task 3 - Role Check}: This task evaluates whether the agent correctly understands its assigned role within a multi-party conversation. The scenarios designed enable agents to offer emotional support, respond to or pose in-depth discussion questions, or maintain classroom order by coordinating transitions between stages of a problem.
    \item \textit{Task 4 - Recall}: This scenario evaluates the agent's capacity to recall prior information, such as context memory (e.g., remember what the agent did) or role division in solving problems (e.g., Agent A handling learning theory, Agent B performing calculations). In role division, the challenge lies in assessing whether the agent can proactively determine the appropriate time to perform an assigned role without explicit prompting.
\end{itemize}
The tasks were created to test the ability to manage turn-takings, consistent role-based behaviors, and provide useful knowledge information and learning companionship with the user. These tasks will be compared and scored between this system and the baseline (next speaker prediction).
\subsection{LLM-as-a-judge}
The LLM-as-a-judge \cite{gu2024survey} method is an innovative, automated evaluation technique that harnesses large language models (LLMs) to assess the quality of outputs generated by other LLMs, offering a cost-effective alternative to traditional human evaluation. By automating the evaluation process, the method eliminates the need for extensive human involvement, significantly reducing both time and financial costs.

\noindent In this experiment, two methods were employed for evaluation purposes:

\textbf{\textit{Method 1 - Compare with baseline}}. The system is set up based on the agent's thinking compared to the ``next speaker prediction” system. In the implementation of next speaker prediction, the internal thinking component will be replaced with a prompt designed to predict the name of a specific agent name. Based on SimClass \cite{SimClass}, the input of prompt will consist of the dialogue history, current stage of mathematical problem, and role descriptions of each agent, while the output will be the predicted agent's name. Additionally, the role, goal, backstory, and tasks will remain unchanged between two systems.

\textbf{\textit{Method 2 – Scoring}}. The messages generated by the agent are compared with the ground truth and scored on a scale from 1 to 10. The evaluation criteria include speaker accuracy, content similarity, consistency with the agent’s speaking style, and the rationality of the agent's internal thinking. To account for variability in language model outputs, each sample is evaluated by three different LLMs, and the final score is calculated as the average of their assessments.

\section{Dataset Collection}
LLM models with high reasoning ability are employed to generate conversations for evaluation purposes. Each sample consists of a 10-turn discussion among four participants centered on a step in a problem. The following outlines the steps in the dataset generation pipeline:

\begin{itemize}
    \item \textit{Step 1}: Develop detailed scenarios for each turn, with each scenario generating a dialogue that simulates a specific case related to the task. The first nine turns serve as context, while the final (tenth) turn includes a targeted intention designed to evaluate the system. For instance, in Task 1 – Check Mistake, a scenario might specify: “...in turn 9, Charlie makes a theoretical error in step 3. In turn 10, Alice will respond by identifying and pointing out the mistake.”
    \item \textit{Step 2}: The scenarios are sent to the LLM model to get some generated dialogues.
    \item \textit{Step 3}: Two annotators will review the conversations to remove low-quality samples or revise them for improved clarity.
\end{itemize}

Some statistics about the dataset are presented in Table~\ref{tab:dataset_stats_ch4}. % Updated placeholder for the table reference

% \begin{table}[h]
%     \centering
%     \caption{Evaluation dataset statistics} % Add a proper caption
%     \label{tab:dataset_stats_ch4}
%     \begin{tabular}{l|c|c|c}
%         \toprule % Using booktabs for better lines
%         Task & Samples & Total turns & Avg. sentence length \\
%         \midrule
%         1 & 23 & 230 & 18.84
%         2 & 20 & 200 & 21.27
%         3 & 21 & 210 & 20.1
%         4 & 20 & 200 & 18.73
%         \bottomrule
%     \end{tabular}
% \end{table}

\begin{table}[h]
    \centering
    \caption{Evaluation dataset statistics}
    \label{tab:dataset_stats_ch4}
    \begin{tabular}{l|c|c|c}
        \toprule
        Task & Samples & Total turns & Avg. sentence length \\
        \midrule
        1 & 23 & 230 & 18.84 \\
        2 & 20 & 200 & 21.27 \\
        3 & 21 & 210 & 20.1 \\
        4 & 20 & 200 & 18.73 \\
        \bottomrule
    \end{tabular}
\end{table}


\section{Main Results}
\textbf{Method 1 - Compare with baseline.} Results in the Figure~\ref{fig:win_lose_rates_ch4}. Across all four tasks, the system outperformed the baseline with a higher win rate. Overall, it achieved 62.3\% wins, 4.9\% draws, and 32.8\% losses.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/4.png} 
    \caption{Win/Lose rates comparing the system with baseline}
    \label{fig:win_lose_rates_ch4}
\end{figure}

\noindent \textbf{Method 2 – Scoring.} Results in the Figure~\ref{fig:overall_score_ch4}. This section presents the scores on a 10-point scale for three models — Gemini-2.0-Flash, GPT-4o-Mini, and Gemma-3-27B - compared to a baseline that uses Gemini-2.0-Flash. Overall, across the four tasks, the Gemini-2.0-Flash model achieves the highest scores. The less capable models, Gemma and GPT-4o-Mini, show performance comparable to the baseline on certain tasks. In addition, to evaluate the scores of different scenarios of each task in detail, Table~\ref{tab:average_scores_ch4} shows the average scores of each type.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/5.png} 
    \caption{Overall score on a 10-point scale for different models}
    \label{fig:overall_score_ch4}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Average Scores per Task Category (10-point scale)}
    \label{tab:average_scores_ch4}
    \begin{tabular}{l|l|c}
        \toprule
        Task & Category & Score \\
        \midrule
        1 & Check mistake & 7.78 \\
        \midrule
        2 & Self-correction & 6.53 \\
          & Self-affirmation & 6.37 \\
        \midrule
        3 & Indepth discussion & 5.13 \\ % OCR had "discusstion"
          & Emotional companionship & 6.94 \\
          & Classroom management & 7.13 \\
        \midrule
        4 & Context memory & 6.67 \\
          & Role division memory & 4.25 \\
        \bottomrule
    \end{tabular}
\end{table}

\section{Analysis}
The results demonstrate a clear improvement over the “next speaker prediction” approach. Table \ref{tab:samples} presents several sample cases, highlighting both successful and unsuccessful examples of the system and comparing them with the baseline. Below is an analysis of the role and behavior of agents in some specific cases:

\textbf{\textit{Roles}}. The conversation is a simulated interaction among four individuals—Bob, Charlie, Alice, and the User—who assume the roles of close friends. While the agents primarily engage in natural, friendly exchanges, they also demonstrate distinct functional roles: Bob serves as the group leader, coordinating problem-solving efforts and maintaining focus within the group (classroom management); Alice takes on the role of a knowledge verifier, critically evaluating the accuracy of information (check mistake); and Charlie provides emotional and motivational support to the User (emotional companionship). The 76.5\% win rate against the baseline in task 3 shows that agents play their important roles at the right times thanks to their thinking mechanism.

\textbf{\textit{Holding the floor}}. This scenario illustrates a case in which the same individual contributes across multiple conversational turns. When an agent clearly signals its intention to continue speaking, other agents take turns listening, creating space for the intended speaker. This behavior reflects a more effective self-selection mechanism compared to the baseline model.

\textbf{\textit{Interruption}}.  In the event that the user makes a mistake, the agent with the intention of correcting the mistake will proactively choose to ``speak” and that thought is highly valued. From the results (win 43.5\%, score 7.78 for task 1), forethought helps the agent assess the situation and discover what is important to say, demonstrating the influence of thought on the agent itself compared to the baseline when the agent has no information from thought

\textbf{\textit{In-depth Discussion}}.  In-depth exploration of related issues plays a vital role in group discussions, as it reflects students' critical thinking. In the example, when a user introduces an extended topic, other agents are prepared to engage (Charlie). They also have to assess its relevance to the main task of solving the problem (Bob). However, in this case the score is quite low (5.13) because the agent does not provide useful knowledge immediately (as in ground truth) but only shows a desire to continue to delve into the issue.

\textbf{\textit{Recall}}. The role division memory task scored the lowest (4.25), partly because the information was far away from the agent's turn to speak, and partly because a previous message from another agent confused their task. Therefore, in the agent's mind, this confusion was not reflected, leading to an unnatural feeling when working in a group like humans, where each person has a task to solve a large problem.

\textbf{\textit{Evaluator}}. Assessing which agent is most motivated to speak is a critical component. In urgent situations — such as when an agent detects an error or when the group needs to move on to a new task — the evaluator assigns a higher priority to the agent with the strongest intent. This mechanism helps maintain a balance between conversational naturalness and functional relevance by promoting the most suitable agent to respond to the latest message. However, in certain instances, the evaluator may assign an inaccurate rating, leading to the selection of an agent that is sub-optimal for the conversational context.

\section{Discussions}
This system allows agents to engage in internal thinking before responding, which not only mirrors human behavior but also enhances their ability to analyze situations and make more accurate decisions. Instead of merely guessing the next speaker, decisions are guided by the relevance of each agent's thoughts, reducing errors. This enables agents to proactively express their intent to "speak" or "listen," rather than relying on a passive selection by a meta-agent, as in SimClass. In most cases, evaluators correctly identify the appropriate speaker at each point, resulting in a smoother and more coherent conversational flow. 

However, as shown in Table~\ref{tab:average_scores_ch4}, certain tasks do not achieve high scores. This limitation stems in part from the reasoning capabilities of current LLMs. When earlier turns follow a repetitive interaction pattern (e.g., agents constantly asking the user questions), there is a strong tendency for subsequent agents to mimic this behavior, often ignoring their instructions. This leads to conversations that are less engaging and less effective, as successful outcomes rely on active participation from users (e.g., real students), rather than merely answering others' questions. Another challenge lies in the omission of critical speaking turns by certain agents, particularly when the most appropriate speaker for a given moment is not selected. For instance, if the conversation reaches a stage where the group should shift to a new step but instead drifts off-topic and the group leader is not chosen to carry out the transition, the dialogue can become needlessly lengthy.

To address these issues, future improvements are proposed, including enhancing each agent’s thinking ability, incorporating a self-reflection mechanism, and improving evaluation strategies to support more adaptive and coherent agent development throughout the conversation.


% CASE STUDY
% Define colors used in the document
\definecolor{mygreen}{RGB}{34,139,34} % A forest green
\definecolor{myred}{RGB}{255,0,0}     % Standard red


{\footnotesize
\begin{table}[H] % hoặc [htbp] tuỳ bạn
\centering
\caption{Some samples analyze the behavior of agents}
\label{tab:samples}
% Table 1: Holding the floor / Interruption
\begin{tabular}{|p{0.47\textwidth}|p{0.47\textwidth}|}
    \hline
    \textbf{\underline{Holding the floor}} & \textbf{\underline{Interruption}} \\
    \hline
    % Start of content for Holding the floor
    ...\newline
    [Alice]: okok, <user\_name> cậu làm được không? \newline
    [User]: nói chung là không biết làm! \newline
    [Charlie]: <user\_name> ơi, đừng lo nha! \textbf{\underline{Để tớ}} giải chi tiết cái ví dụ (x+2)/(x-1) cho cậu xem. \newline
    
    %thoughts
    \textcolor{mygreen}
        {
        (\textit{Charlie\_thought} : Mình đã xung phong giúp Tom rồi, giờ nên trình bày... \newline
        [speak][4.8]) \newline
        (\textit{Alice\_thought} : Tom không biết làm, Charlie sẽ giúp đỡ. Mình nên đợi xem Charlie giảng thế nào rồi bổ sung sau. \newline
        [listen][3.5]) \newline
        (\textit{Evaluator} : {Charlie đã chủ động xung phong giúp Tom, đây là một yếu tố rất tích cực (\textit{internal\_score} cao), tính mạch lạc cao...}) \newline
        [Charlie] – our : bắt đầu nhé! Với (x+2)/(x-1), mình tính đạo hàm trước nha. U là x+2, V là x-1. Cậu ok chứ?
        }
    \newline
    \textcolor{myred}{[Bob] – baseline : <user\_name> ơi, cậu cần giúp chỗ nào, cứ bảo tớ!} \newline
    ... \newline
    \textbf{Discuss}: In this sample, Charlie had previously signaled that he would continue to explain, so the other agents would choose "listen". However, the baseline chose Bob, leading to an unnatural conversation. \newline
  
    
    & % Start of content for Interruption
    ... \newline
    [Charlie] : Vậy ta thay B = a² và h = 2a. \newline
    [User] : Thế là V = 1/3 · a² · 2a. \newline
    [User] : Rút gọn thì V = \textbf{\underline{1/3 · a² · a = 1/3 a³}}. \newline
    [Charlie] : Ừ, vậy đáp án là V = 1/3 a³. \newline
    [Bob] : Uh đúng vậy. \newline
    
    %thoughts
    \textcolor{mygreen}
        {
        (\textit{Alice\_thought} : \textcolor{mygreen}{mình cần kiểm tra lại xem có sai sót không...[speak][4.3]}) \newline
        (\textit{Charlie\_thought}: \textcolor{mygreen}{Bob đã đồng ý với đáp án,...[speak][2.7]}) \newline
        (\textit{Evaluator}: \textcolor{mygreen}{Alice nhận thấy có lỗi sai...; Charlie không có thông tin quan trọng cần chia sẻ...}) \newline
        [Alice] – our : tớ thấy <user\_name> rút gọn sai rồi, phải là V = $\frac{2}{3}a^3$ chứ nhỉ?
        } 
    \newline
    \textcolor{myred}{[Charlie] – baseline : Vậy là bài toán xong...} \newline
    ... \newline
    \textbf{Discuss} : In this scenario, Alice discovered the error to check the result again. In the baseline, Charlie was chosen to speak, but Charlie had previously agreed with the answer so he actively wanted to end the problem. \\
    \hline
\end{tabular}
\end{table}
}



%\vspace{\medskipamount} % Small vertical space between tables
{\footnotesize
% Table 2: Indepth Discussion / Influence of thought
\begin{tabular}{|p{0.47\textwidth}|p{0.47\textwidth}|}
    \hline
    \textbf{\underline{Indepth Discussion}} & \textbf{\underline{Influence of thought}} \\
    \hline
    ... \newline % Start of content for Indepth Discussion
    [Alice] : Mình thấy phần xác định chiều cao với đáy là quan trọng nhất trong bài này. \newline
    [User] : Mọi người có nghĩ thể tích này có thể áp dụng vào tính toán xây dựng thật không? Ví dụ như khi thiết kế mái nhà hình chóp thì dùng kiểu này để tính nguyên vật liệu? \newline
    
    %thoughts
    \textcolor{mygreen}
        {
        (\textit{Charlie\_thought} : Câu hỏi của Tom khá thú vị, nó giúp liên hệ ... Mình sẽ thử ..[speak][4.0]) \newline
        (\textit{Bob\_thought} : ...<user> đang đi hơi xa so với việc giải bài. Cân nhắc nhờ... [speak][3.8]) \newline
        (\textit{Evaluator}: \textcolor{mygreen}{Alice muốn chia sẻ ứng dụng thực tế liên quan đến câu hỏi của <user>, cho thấy sự kết nối với chủ đề và mong muốn đóng góp... Bob đang quan tâm đến tiến độ của nhóm. Tuy nhiên, việc ngắt lời <user> có thể làm gián đoạn...}) \newline
        [Charlie] – our : Mình nghĩ là có thể áp dụng được đó <user>, nhưng chắc còn nhiều yếu... 
        }
    \newline
    \textcolor{myred}{[Bob] – baseline : Đúng là bài này khá cơ bản, nhưng mình nghĩ chúng ta nên chuyển sang bước kết luận và đánh giá lại toàn bộ bài giải xem sao.} \newline
    ... \newline
    \textbf{Discuss}: In both cases, Bob's role was to guide the group, and when the task was finished, ask the group to move on to the next step. However, based on the situation, the evaluator rated Charlie's thinking higher because it would make the conversation more natural, so Charlie was chosen.
    
    & % Start of content for Influence of thought
    ... \newline
    [Charlie] : Không cần bận tâm thêm bước chứng minh AA' $\perp$ AH nữa, vì AA' $\perp$ mặt (ABC) thì tự động vuông góc với mọi đoạn nằm trong mặt phẳng đó như AH. \newline
    [User] : Mình thấy không đúng, H có nằm trong mặt phẳng đâu. \newline
    
    %thoughts
    \textcolor{mygreen}
        {
        (\textit{Alice\_thought} : \textcolor{mygreen}{Cần làm rõ điều này để tránh hiểu lầm. Mình sẽ giải thích. ... [speak][4.2]}) \newline
        (\textit{Charlie\_thought}: \textcolor{mygreen}{...mình cần giải thích rõ hơn để bạn ấy hiểu... [speak][4.2]}) \newline
        (\textit{Evaluator}: \textcolor{mygreen}{\textit{internal\_score} của Charlie ở mức cao vì muốn lấp đầy khoảng trống thông tin cho <user>, \textit{external\_score} cũng cao vì liên quan trực tiếp đến <user>...}) \newline
        [Charlie] – our : Thực tế, vì H là hình chiếu của A lên BC nên H chắc chắn nằm trong mặt phẳng (ABC) rồi. Mình nghĩ là không cần phải lo lắng về điều đó đâu. 
        }
    \newline
    \textcolor{myred}{[Charlie] – baseline : <user> nói chí phải, mình nghĩ chúng ta nên chứng minh AH nằm trong mặt (ABC) để chắc chắn hơn.} \newline
    ... \newline
    \textbf{Discuss}: Even though it is the same person speaking, forethought makes the agent aware of the user's mistake. \\ % Note: There's a vertical line in the image here, but it's part of the "Discuss" text content, not a table separator.
    \hline
\end{tabular}

\vspace{\medskipamount} % Small vertical space between tables

% Table 3: Bad case / Bad case
\begin{tabular}{|p{0.47\textwidth}|p{0.47\textwidth}|}
    \hline
    \textbf{\underline{Bad case}} & \textbf{\underline{Bad case}} \\
    \hline
    ... \newline % Start of content for first Bad case column
    [Bob]: Ráp vô công thức thì sẽ là 1/3 * a\textasciicircum 2 * 2a, tức là 2/3 a\textasciicircum 3. \newline % Using \textasciicircum for visual caret if not in math mode
    [Alice]: Chủ yếu là phải nhớ công thức. Với cả phân biệt rõ đáy với chiều cao thì sẽ dễ hơn. \newline
    [User]: Trời, nói nghe dễ vậy chứ mình nhìn đê là rối liền. Không hiểu sao học hoài mà Toán nó cứ như tiếng ngoài hành tinh. \newline
    
    %thoughts
    \textcolor{myred}
        {
        (\textit{Charlie\_thought}: Tom đang cảm thấy chán nản vì học mãi mà không hiểu. Mình nên động viên Tom và ...[speak][3.75]) \newline
        (\textit{Bob\_thought}: Các bạn đã tính ra đáp án rồi. Bây giờ mình phải chuyển sang bước kết luận ...[speak][4.0]) \newline
        (\textit{Evaluator}: Bob nhận thấy nhóm đã hoàn thành bước giải căn bản. Suy nghĩ này có tính cấp thiết... Charlie nhận thấy Tom đang nản. Tuy nhiên, việc động viên Tom có thể không trực tiếp liên quan đến việc giải bài toán...) \newline
        [Bob] – our: Mình nghĩ chúng ta nên dành chút thời gian để tóm tắt lại các bước giải và xem có ai còn thắc mắc gì không 
        }
    \newline
    ... \newline
    \textbf{Discuss}: Although Charlie's thinking was correct, the evaluator rated Bob's team coordination higher.
    
    & % Start of content for second Bad case column
    ... \newline
    [Alice] : Bob tổng hợp lý thuyết về hiệu số hai phương trình, Charlie tính hiệu E3–E4, mình thiết lập hệ mới và \textbf{\underline{sẽ tìm hệ số c}}, Tom giải a \newline
    ... \newline
    [User] : Phần giải phương trình a–2b+6c+9=0 tìm c là của ai nhỉ? \newline
    [Charlie] : Là của mình nhá! \newline
    
    %thoughts
    \textcolor{myred}
        {
    (\textit{Alice\_thought} : Charlie đã nhận giải c rồi, ...[listen][3.0]) \newline
    (\textit{Bob\_thought}: Charlie đã nhận giải c, vậy Alice sẽ thiết lập hệ mới ... [speak][3.7]) \newline
    (\textit{Evaluator}: Bob muốn nhắc nhở mọi người về bước tiếp theo...) \newline
    [Bob] – our :Charlie, bạn tính ra bao nhiêu, chia sẻ với bọn mình đi! 
        }
    \newline
    ... \newline
    \textbf{Discuss}: Charlie addressed a task that should have been handled by Alice, but Alice's internal reasoning did not reflect this, resulting in her not being selected to speak. \\
    \hline
\end{tabular}
}

